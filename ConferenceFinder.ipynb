{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Base URL\n",
        "base_url = 'http://www.wikicfp.com/cfp/call?conference=computer%20science&page='\n",
        "\n",
        "# Keyword to search for\n",
        "keyword = 'computer science'\n",
        "\n",
        "# Initialize a list to store the data\n",
        "data = []\n",
        "\n",
        "# Loop through the first 10 pages\n",
        "for page in range(1, 11):\n",
        "    # Modify URL for each page\n",
        "    url = base_url + str(page)\n",
        "\n",
        "    # Send a GET request\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Check if request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Parse HTML\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Find all table rows\n",
        "        rows = soup.find_all('tr')\n",
        "\n",
        "        # Iterate over each row\n",
        "        for i in range(len(rows)):\n",
        "            if rows[i].find('a'):  # Check if the row contains a link\n",
        "                name_row = rows[i]\n",
        "                details_row = rows[i + 1] if i + 1 < len(rows) else None\n",
        "\n",
        "                # Check if the row contains the keyword and details_row is not None\n",
        "                if details_row and keyword.lower() in name_row.text.lower():\n",
        "                    # Try to extract details\n",
        "                    name_td = name_row.find('td', {'align': 'left', 'colspan': '3'})\n",
        "                    date_tds = details_row.find_all('td', {'align': 'left'})\n",
        "\n",
        "                    # Check if all elements are present\n",
        "                    if name_td and len(date_tds) == 3:\n",
        "                        name = name_td.text.strip()\n",
        "                        dates = date_tds[0].text.strip()\n",
        "                        place = date_tds[1].text.strip()\n",
        "                        deadline = date_tds[2].text.strip()\n",
        "\n",
        "                        # Skip if it matches the header format\n",
        "                        if dates == \"Event\" and place == \"When\" and deadline == \"Where\":\n",
        "                            continue\n",
        "\n",
        "                        # Append the data\n",
        "                        data.append({\n",
        "                            \"Name\": name,\n",
        "                            \"Dates\": dates,\n",
        "                            \"Place\": place,\n",
        "                            \"Deadline\": deadline\n",
        "                        })\n",
        "\n",
        "    else:\n",
        "        print(f\"Failed to retrieve page {page}.\")\n",
        "\n",
        "# Create a DataFrame from the data\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "# Add a new column 'Country'\n",
        "df['Country'] = df['Place'].apply(lambda x: 'Online' if 'online' in x.lower() or 'virtual' in x.lower() else x.split(', ')[-1])\n",
        "\n",
        "# Remove missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Calculate the distribution of places\n",
        "distribution = df['Country'].value_counts()\n",
        "\n",
        "df.head()\n",
        "# Print the top and bottom countries\n",
        "print(\"Top Countries:\")\n",
        "print(distribution.head())\n",
        "print(\"\\nBottom Countries:\")\n",
        "print(distribution.tail())\n"
      ],
      "metadata": {
        "id": "Z2WQ8wOu5JIK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}